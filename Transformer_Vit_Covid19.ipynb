{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer-Vit-Covid19.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOO3kOw0hN5Z3SI5U48dINY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alifarki/ViT-pytorch/blob/main/Transformer_Vit_Covid19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-uzV4cYVSQy",
        "outputId": "7d781421-a9ee-479c-d047-af15b1856ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  9 12:23:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Alifarki/ViT-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOuOuu11Yi3Q",
        "outputId": "480cbd9b-d8ca-4433-f7ac-7b170bcd1752"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ViT-pytorch'...\n",
            "remote: Enumerating objects: 170, done.\u001b[K\n",
            "remote: Total 170 (delta 0), reused 0 (delta 0), pack-reused 170\u001b[K\n",
            "Receiving objects: 100% (170/170), 21.20 MiB | 32.26 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ViT-pytorch/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4znbQ66hZetU",
        "outputId": "f229a85b-66ef-4ce7-f87a-4708905f8645"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ViT-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir checkpoint"
      ],
      "metadata": {
        "id": "05lINw1dZjjB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd checkpoint/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptm-gn4sijFs",
        "outputId": "a990a7d8-3f36-4ebe-e48f-8e6f5ec536ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ViT-pytorch/checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/vit_models/imagenet21k%2Bimagenet2012/ViT-B_16.npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFcLylmeh-qy",
        "outputId": "bf66f8e8-53a1-4635-91c6-9ca5fd16f1ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-09 12:24:08--  https://storage.googleapis.com/vit_models/imagenet21k%2Bimagenet2012/ViT-B_16.npz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 108.177.98.128, 74.125.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347502902 (331M) [application/octet-stream]\n",
            "Saving to: ‘ViT-B_16.npz’\n",
            "\n",
            "ViT-B_16.npz        100%[===================>] 331.40M  53.7MB/s    in 6.2s    \n",
            "\n",
            "2022-07-09 12:24:15 (53.7 MB/s) - ‘ViT-B_16.npz’ saved [347502902/347502902]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/ViT-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yAXz_aLh-Jw",
        "outputId": "02b378e9-8d27-4080-93b1-741bd8f8082a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ViT-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/apex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDQAGIDuZlhv",
        "outputId": "49cae494-ed63-4b88-ddc6-76972d9ab4ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 9901, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 9901 (delta 4), reused 6 (delta 0), pack-reused 9881\u001b[K\n",
            "Receiving objects: 100% (9901/9901), 14.85 MiB | 30.11 MiB/s, done.\n",
            "Resolving deltas: 100% (6809/6809), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd apex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQM9DzsiZoPB",
        "outputId": "28910128-cbc1-4945-8595-2994bba2c7bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ViT-pytorch/apex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -v --disable-pip-version-check --no-cache-dir ./"
      ],
      "metadata": {
        "id": "lJwFZjUWZoFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-g1J-pCZn77",
        "outputId": "abfed8aa-bf75-48f4-8b74-db647e6fa6ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ViT-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ml_collections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6_mXBuiZnxq",
        "outputId": "c1673d09-71de-4239-adfc-ba99b9423b77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ml_collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml_collections) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml_collections) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml_collections) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml_collections) (0.5.5)\n",
            "Building wheels for collected packages: ml-collections\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=12f2148359882b5d1f99036b9c41ee6208a93aabeed68838c95ed6f819e0a236\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n",
            "Successfully built ml-collections\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90i-BDk2WknY",
        "outputId": "14ce87b4-9adc-43b3-cc21-e4f0d095048f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/drive/MyDrive/csc532.zip /content/ViT-pytorch/Data-cov"
      ],
      "metadata": {
        "id": "XT4yelmBWl63"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd Data-cov/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBGbacejacf8",
        "outputId": "a3be748c-c341-4ef5-80ed-64696f1e595b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ViT-pytorch/Data-cov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip csc532.zip"
      ],
      "metadata": {
        "id": "nyJ4MlNMXHHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, resnet34\n",
        "import os"
      ],
      "metadata": {
        "id": "6CnZyaeUXe7H"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from shutil import copyfile\n",
        "# from scipy.io import loadmat\n",
        "\n",
        "# images_path = \"./JPEGImages\"\n",
        "# labels_path = \"./ImageSplits\"\n",
        "# new_dataset_path = \"./StanfordActionDataset\"\n",
        "\n",
        "# if not(os.path.exists(new_dataset_path)):\n",
        "#     os.mkdir(new_dataset_path)\n",
        "#     os.mkdir(new_dataset_path + '/' + 'train')\n",
        "#     os.mkdir(new_dataset_path + '/' + 'test')\n",
        "\n",
        "# txts = os.listdir(labels_path)\n",
        "# for txt in txts:\n",
        "#     idx = txt[0:-4].rfind('_')\n",
        "#     class_name = txt[0:idx]\n",
        "#     if class_name in ['actions.tx', 'test.tx', 'train.tx']:\n",
        "#       continue\n",
        "#     train_or_test = txt[idx+1:-4]\n",
        "#     txt_contents = open(labels_path + '/' + txt)\n",
        "#     txt_contents = txt_contents.read()\n",
        "#     image_names  = txt_contents.split('\\n')\n",
        "#     num_aid_images_per_class = 1\n",
        "#     for image_name in image_names[0:-1]:\n",
        "#         if not(os.path.exists(new_dataset_path + '/' + train_or_test + '/' + class_name)):\n",
        "#             os.mkdir(new_dataset_path + '/' + train_or_test + '/' + class_name)\n",
        "#         copyfile(images_path + '/' + image_name,\n",
        "#                  new_dataset_path + '/' + train_or_test + '/' + class_name + '/' + image_name)\n",
        "        "
      ],
      "metadata": {
        "id": "JtSPtpoZ29Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Data\n",
        "# transform_train = transforms.Compose([\n",
        "# transforms.Resize((224, 224)),\n",
        "# transforms.ToTensor(),\n",
        "# ])\n",
        "# transform_test = transforms.Compose([\n",
        "# transforms.Resize((224, 224)),\n",
        "# transforms.ToTensor(),\n",
        "# ])\n",
        "# trainset = datasets.ImageFolder(root='/content/ViT-pytorch/Data-cov/datasets/datasets/train/',\n",
        "# transform=transform_train)\n",
        "# trainloader = torch.utils.data.DataLoader(\n",
        "# trainset, batch_size=16, shuffle=True, num_workers=2)\n",
        "# # testset = torchvision.datasets.CIFAR100(\n",
        "# # root='./data', train=False, download=True, transform=transform_test)\n",
        "# testset = datasets.ImageFolder(root='/content/ViT-pytorch/Data-cov/datasets/datasets/test/',\n",
        "# transform=transform_test)\n",
        "# testloader = torch.utils.data.DataLoader(\n",
        "# testset, batch_size=16, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "-NDhwfHTXo1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python train.py --name stanford40-1 --dataset stanford40 --model_type ViT-B_16 --pretrained_dir checkpoint/ViT-B_16.npz --fp16 --fp16_opt_level O2 --gradient_accumulation_steps 16"
      ],
      "metadata": {
        "id": "F8kTsy_KA2wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/ViT-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibD0GUf2gZfs",
        "outputId": "85553d65-ae9c-41f4-aa3f-81aa48ad3615"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ViT-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --name cov19 --dataset cov19 --model_type ViT-B_16  --fp16 --fp16_opt_level O2 --gradient_accumulation_steps 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6z8MwafYFVP",
        "outputId": "7e63269f-fe46-456e-fee1-d8f4cc49045e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "07/09/2022 12:29:51 - WARNING - __main__ - Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
            "07/09/2022 12:29:52 - INFO - models.modeling - load_pretrained: resized variant: torch.Size([1, 577, 768]) to torch.Size([1, 197, 768])\n",
            "load_pretrained: grid-size from 24 to 14\n",
            "07/09/2022 12:30:04 - INFO - __main__ - classifier: token\n",
            "hidden_size: 768\n",
            "patches:\n",
            "  size: !!python/tuple [16, 16]\n",
            "representation_size: null\n",
            "transformer: {attention_dropout_rate: 0.0, dropout_rate: 0.1, mlp_dim: 3072, num_heads: 12,\n",
            "  num_layers: 12}\n",
            "\n",
            "07/09/2022 12:30:04 - INFO - __main__ - Training parameters Namespace(dataset='cov19', decay_type='cosine', device=device(type='cuda'), eval_batch_size=64, eval_every=100, fp16=True, fp16_opt_level='O2', gradient_accumulation_steps=16, img_size=224, learning_rate=0.03, local_rank=-1, loss_scale=0, max_grad_norm=1.0, model_type='ViT-B_16', n_gpu=1, name='cov19', num_steps=10000, output_dir='output', pretrained_dir='checkpoint/ViT-B_16.npz', seed=42, train_batch_size=512, warmup_steps=500, weight_decay=0)\n",
            "07/09/2022 12:30:04 - INFO - __main__ - Total Parameter: \t85.8M\n",
            "85.800194\n",
            "07/09/2022 12:30:06 - INFO - numexpr.utils - NumExpr defaulting to 4 threads.\n",
            "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
            "07/09/2022 12:30:09 - INFO - __main__ - ***** Running training *****\n",
            "07/09/2022 12:30:09 - INFO - __main__ -   Total optimization steps = 10000\n",
            "07/09/2022 12:30:09 - INFO - __main__ -   Instantaneous batch size per GPU = 32\n",
            "07/09/2022 12:30:09 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 512\n",
            "07/09/2022 12:30:09 - INFO - __main__ -   Gradient Accumulation steps = 16\n",
            "Training (X / X Steps) (loss=X.X):  68% 15/22 [00:09<00:03,  1.81it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n",
            "Training (1 / 10000 Steps) (loss=0.69336):  68% 15/22 [00:10<00:03,  1.81it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "Training (1 / 10000 Steps) (loss=0.69336): 100% 22/22 [00:13<00:00,  1.65it/s]\n",
            "Training (2 / 10000 Steps) (loss=0.69336): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (3 / 10000 Steps) (loss=0.69189): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (4 / 10000 Steps) (loss=0.68945): 100% 22/22 [00:12<00:00,  1.69it/s]\n",
            "Training (5 / 10000 Steps) (loss=0.68799): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (6 / 10000 Steps) (loss=0.66699): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (7 / 10000 Steps) (loss=0.66553): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (8 / 10000 Steps) (loss=0.65918): 100% 22/22 [00:12<00:00,  1.70it/s]\n",
            "Training (9 / 10000 Steps) (loss=0.65332): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (10 / 10000 Steps) (loss=0.57764): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (11 / 10000 Steps) (loss=0.58496): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (12 / 10000 Steps) (loss=0.49219): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (13 / 10000 Steps) (loss=0.50391): 100% 22/22 [00:13<00:00,  1.66it/s]\n",
            "Training (14 / 10000 Steps) (loss=0.50684): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (15 / 10000 Steps) (loss=0.38501): 100% 22/22 [00:12<00:00,  1.74it/s]\n",
            "Training (16 / 10000 Steps) (loss=0.26978): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (17 / 10000 Steps) (loss=0.33813): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (18 / 10000 Steps) (loss=0.58301): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (19 / 10000 Steps) (loss=0.61035): 100% 22/22 [00:12<00:00,  1.70it/s]\n",
            "Training (20 / 10000 Steps) (loss=0.62744): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (21 / 10000 Steps) (loss=0.62939): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (22 / 10000 Steps) (loss=0.43530): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (23 / 10000 Steps) (loss=0.70752): 100% 22/22 [00:12<00:00,  1.70it/s]\n",
            "Training (24 / 10000 Steps) (loss=0.61426): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (25 / 10000 Steps) (loss=0.49023): 100% 22/22 [00:13<00:00,  1.61it/s]\n",
            "Training (26 / 10000 Steps) (loss=0.31274): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (27 / 10000 Steps) (loss=0.35864): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (28 / 10000 Steps) (loss=0.32471): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (29 / 10000 Steps) (loss=0.54199): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (30 / 10000 Steps) (loss=0.50830): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (31 / 10000 Steps) (loss=0.42310): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (32 / 10000 Steps) (loss=0.50684): 100% 22/22 [00:12<00:00,  1.74it/s]\n",
            "Training (33 / 10000 Steps) (loss=0.49707): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (34 / 10000 Steps) (loss=0.32300): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (35 / 10000 Steps) (loss=0.38086): 100% 22/22 [00:12<00:00,  1.70it/s]\n",
            "Training (36 / 10000 Steps) (loss=0.44116): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (37 / 10000 Steps) (loss=0.63135): 100% 22/22 [00:12<00:00,  1.70it/s]\n",
            "Training (38 / 10000 Steps) (loss=0.37939): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (39 / 10000 Steps) (loss=0.43091): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (40 / 10000 Steps) (loss=0.47778): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (41 / 10000 Steps) (loss=0.44946): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (42 / 10000 Steps) (loss=0.33228): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (43 / 10000 Steps) (loss=0.36426): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (44 / 10000 Steps) (loss=0.53760): 100% 22/22 [00:12<00:00,  1.69it/s]\n",
            "Training (45 / 10000 Steps) (loss=0.42798): 100% 22/22 [00:13<00:00,  1.64it/s]\n",
            "Training (46 / 10000 Steps) (loss=0.44849): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (47 / 10000 Steps) (loss=0.21973): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (48 / 10000 Steps) (loss=0.63037): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (49 / 10000 Steps) (loss=0.40723): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (X / X Steps) (loss=X.X):  68% 15/22 [00:09<00:03,  1.83it/s]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
            "Training (50 / 10000 Steps) (loss=0.24292): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (51 / 10000 Steps) (loss=0.23254): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (52 / 10000 Steps) (loss=0.29956): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (53 / 10000 Steps) (loss=0.22375): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (54 / 10000 Steps) (loss=0.33789): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (55 / 10000 Steps) (loss=0.27246): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (56 / 10000 Steps) (loss=0.28198): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (57 / 10000 Steps) (loss=0.19495): 100% 22/22 [00:13<00:00,  1.65it/s]\n",
            "Training (58 / 10000 Steps) (loss=0.16870): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (59 / 10000 Steps) (loss=0.26880): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (60 / 10000 Steps) (loss=0.15808): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (61 / 10000 Steps) (loss=0.18628): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (62 / 10000 Steps) (loss=0.30469): 100% 22/22 [00:12<00:00,  1.70it/s]\n",
            "Training (63 / 10000 Steps) (loss=0.18396): 100% 22/22 [00:12<00:00,  1.74it/s]\n",
            "Training (64 / 10000 Steps) (loss=0.25562): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (65 / 10000 Steps) (loss=0.13550): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (66 / 10000 Steps) (loss=0.32202): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (67 / 10000 Steps) (loss=0.26392): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (68 / 10000 Steps) (loss=0.19116): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (69 / 10000 Steps) (loss=0.13477): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (70 / 10000 Steps) (loss=0.29761): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (71 / 10000 Steps) (loss=0.28052): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (72 / 10000 Steps) (loss=0.27124): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (73 / 10000 Steps) (loss=0.05753): 100% 22/22 [00:13<00:00,  1.66it/s]\n",
            "Training (74 / 10000 Steps) (loss=0.25610): 100% 22/22 [00:12<00:00,  1.70it/s]\n",
            "Training (75 / 10000 Steps) (loss=0.26440): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (76 / 10000 Steps) (loss=0.24146): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (77 / 10000 Steps) (loss=0.03656): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (78 / 10000 Steps) (loss=0.33374): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (79 / 10000 Steps) (loss=0.07715): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (80 / 10000 Steps) (loss=0.16772): 100% 22/22 [00:13<00:00,  1.67it/s]\n",
            "Training (81 / 10000 Steps) (loss=0.06116): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (82 / 10000 Steps) (loss=0.08136): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (83 / 10000 Steps) (loss=0.16125): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (84 / 10000 Steps) (loss=0.33936): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (85 / 10000 Steps) (loss=0.11383): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (86 / 10000 Steps) (loss=0.01607): 100% 22/22 [00:12<00:00,  1.74it/s]\n",
            "Training (87 / 10000 Steps) (loss=0.02609): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (88 / 10000 Steps) (loss=0.07245): 100% 22/22 [00:13<00:00,  1.69it/s]\n",
            "Training (89 / 10000 Steps) (loss=0.07477): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (90 / 10000 Steps) (loss=0.13794): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (91 / 10000 Steps) (loss=0.04538): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (92 / 10000 Steps) (loss=0.14172): 100% 22/22 [00:12<00:00,  1.74it/s]\n",
            "Training (93 / 10000 Steps) (loss=0.15527): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (94 / 10000 Steps) (loss=0.08759): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (95 / 10000 Steps) (loss=0.12115): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (96 / 10000 Steps) (loss=0.04605): 100% 22/22 [00:12<00:00,  1.72it/s]\n",
            "Training (97 / 10000 Steps) (loss=0.04297): 100% 22/22 [00:12<00:00,  1.70it/s]\n",
            "Training (98 / 10000 Steps) (loss=0.10400): 100% 22/22 [00:12<00:00,  1.71it/s]\n",
            "Training (99 / 10000 Steps) (loss=0.10876): 100% 22/22 [00:12<00:00,  1.73it/s]\n",
            "Training (100 / 10000 Steps) (loss=0.02644):  68% 15/22 [00:10<00:03,  1.82it/s]07/09/2022 12:51:35 - INFO - __main__ - ***** Running Validation *****\n",
            "07/09/2022 12:51:35 - INFO - __main__ -   Num steps = 7\n",
            "07/09/2022 12:51:35 - INFO - __main__ -   Batch size = 64\n",
            "\n",
            "Validating... (loss=X.X):   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validating... (loss=0.00484):   0% 0/7 [00:02<?, ?it/s]\u001b[A\n",
            "Validating... (loss=0.00484):  14% 1/7 [00:02<00:15,  2.55s/it]\u001b[A\n",
            "Validating... (loss=0.00530):  14% 1/7 [00:02<00:15,  2.55s/it]\u001b[A\n",
            "Validating... (loss=0.00530):  29% 2/7 [00:02<00:06,  1.28s/it]\u001b[A\n",
            "Validating... (loss=0.00943):  29% 2/7 [00:03<00:06,  1.28s/it]\u001b[A\n",
            "Validating... (loss=0.00943):  43% 3/7 [00:03<00:03,  1.17it/s]\u001b[A\n",
            "Validating... (loss=0.00306):  43% 3/7 [00:03<00:03,  1.17it/s]\u001b[A\n",
            "Validating... (loss=0.00306):  57% 4/7 [00:03<00:01,  1.51it/s]\u001b[A\n",
            "Validating... (loss=0.29382):  57% 4/7 [00:04<00:01,  1.51it/s]\u001b[A\n",
            "Validating... (loss=0.29382):  71% 5/7 [00:04<00:01,  1.42it/s]\u001b[A\n",
            "Validating... (loss=0.67699):  71% 5/7 [00:04<00:01,  1.42it/s]\u001b[A\n",
            "Validating... (loss=0.67699):  86% 6/7 [00:04<00:00,  1.70it/s]\u001b[A\n",
            "Validating... (loss=4.64280):  86% 6/7 [00:04<00:00,  1.70it/s]\u001b[A\n",
            "Validating... (loss=4.64280): 100% 7/7 [00:04<00:00,  1.40it/s]\n",
            "07/09/2022 12:51:40 - INFO - __main__ - \n",
            "\n",
            "07/09/2022 12:51:40 - INFO - __main__ - Validation Results\n",
            "07/09/2022 12:51:40 - INFO - __main__ - Global Steps: 100\n",
            "07/09/2022 12:51:40 - INFO - __main__ - Valid Loss: 0.80518\n",
            "07/09/2022 12:51:40 - INFO - __main__ - Valid Accuracy: 0.89216\n",
            "07/09/2022 12:51:41 - INFO - __main__ - Saved model checkpoint to [DIR: output]\n",
            "Training (100 / 10000 Steps) (loss=0.02644): 100% 22/22 [00:18<00:00,  1.19it/s]\n",
            "Training (101 / 10000 Steps) (loss=0.09821): 100% 22/22 [00:13<00:00,  1.68it/s]\n",
            "Training (X / X Steps) (loss=X.X):  64% 14/22 [00:09<00:05,  1.47it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 332, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 328, in main\n",
            "    train(args, model)\n",
            "  File \"train.py\", line 206, in train\n",
            "    scaled_loss.backward()\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
            "    optimizer._post_amp_backward(loss_scaler)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/apex/amp/_process_optimizer.py\", line 196, in post_backward_with_master_weights\n",
            "    preexisting_fp32_grads)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/apex/amp/scaler.py\", line 184, in unscale_with_stashed\n",
            "    out_scale/stashed_have_scale)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/apex/amp/scaler.py\", line 148, in unscale_with_stashed_python\n",
            "    self.dynamic)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/apex/amp/scaler.py\", line 22, in axpby_check_overflow_python\n",
            "    cpu_sum = float(model_grad.float().sum())\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch = next(iter(testloader))\n",
        "# batch[0].shape, batch[1].shape"
      ],
      "metadata": {
        "id": "nXW8cq9ib9oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def normalize_image(image):\n",
        "#     image_min = image.min()\n",
        "#     image_max = image.max()\n",
        "#     image.clamp_(min = image_min, max = image_max)\n",
        "#     image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "#     return image\n",
        "\n",
        "# def plot_images(images, labels, classes, normalize=True):\n",
        "\n",
        "#     n_images = len(images)\n",
        "\n",
        "#     rows = int(np.sqrt(n_images))\n",
        "#     cols = int(np.sqrt(n_images))\n",
        "\n",
        "#     fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "#     for i in range(rows*cols):\n",
        "\n",
        "#         ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "#         image = images[i]\n",
        "\n",
        "#         if normalize:\n",
        "#             image = normalize_image(image)\n",
        "\n",
        "#         ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "#         ax.set_title(classes[labels[i]])\n",
        "#         ax.axis('off')"
      ],
      "metadata": {
        "id": "HgbSn2Nl2waX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classes = testset.classes\n",
        "\n",
        "# plot_images(batch[0], batch[1], classes, normalize=True)"
      ],
      "metadata": {
        "id": "U76dQJQJ2wRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k0GzTUA02wHc",
        "outputId": "a4583a14-c4dc-4f19-c0b2-3a7feed7a2aa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ViT-pytorch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40YdoxuGq4ie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de60a95d-89d5-4cd1-c813-114bc2840362"
      },
      "source": [
        "!git pull origin main"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/Alifarki/ViT-pytorch\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmsjGjbddKKM"
      },
      "source": [
        "!git config --global user.email \"alifarki@yahoo.com\""
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y5W5rcedVE0"
      },
      "source": [
        "!git add *.py"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuRr4Eb_pagI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2599e315-85a0-4394-8f0d-4e66833caca3"
      },
      "source": [
        "!git commit -m \"add cov19 Actions\""
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "Changes not staged for commit:\n",
            "\t\u001b[31mmodified:   utils/data_utils.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "\t\u001b[31mData-cov/\u001b[m\n",
            "\t\u001b[31mapex/\u001b[m\n",
            "\t\u001b[31mcheckpoint/\u001b[m\n",
            "\t\u001b[31mlogs/\u001b[m\n",
            "\t\u001b[31moutput/\u001b[m\n",
            "\n",
            "no changes added to commit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv6Ku61Dp0Pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fe5fb0-963a-4327-d92f-61fa4f95bf35"
      },
      "source": [
        "!git push -u origin main"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yD4NnyRwG6US"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}